{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Chronicling America API in C\n",
    "\n",
    "by Cyrus Gomes\n",
    "\n",
    "**LOC Chronicling America API Documentation**: https://chroniclingamerica.loc.gov/about/api/\n",
    "\n",
    "These recipe examples were tested on November, 2023.\n",
    "\n",
    "**Attribution:** We thank ***Professor Jessica Kincaid*** (UA Libraries, Hoole Special Collections) for the use-cases. All data was collected from the Library of Congress, Chronicling America: Historic American Newspapers site, using the API.\n",
    "\n",
    "Note that the data from the Alabama state intelligencer, The age-herald, and the Birmingham age-herald were contributed to Chronicling America by The University of Alabama Libraries: https://chroniclingamerica.loc.gov/awardees/au/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, install the CURL package by typing the following command in the terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install curl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, install the jq package by typing the following command in the terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set a directory where we want the Chronam directory for our projects to be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Chronam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we change the directory to the folder we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Chronam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Basic API request\n",
    "The Chronicling America API identifies newspapers and other records using LCCNs. We can query the API once we have the LCCN for the newspaper and even ask for particular issues and editions. For example, the following link lists newspapers published in the state of Alabama, from which the LCCN can be obtained: https://chroniclingamerica.loc.gov/newspapers/?state=Alabama\n",
    "\n",
    "Here is an example with the Alabama State Intelligencer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can initialize a folder for the current project that we are working on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir APIdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can change to our newly created directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd APIdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilize the `%%file` command to create the following makefile, which will compile our program and create an executable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file makefile\n",
    "\n",
    "# Set the variable CC to gcc, which is used to build the program\n",
    "CC=gcc\n",
    "\n",
    "# Enable debugging information and enable all compiler warnings\n",
    "CFLAGS=-g -Wall\n",
    "\n",
    "# Set the bin variable as the name of the binary file we are creating\n",
    "BIN=api_data\n",
    "\n",
    "# Create the binary file with the name we put\n",
    "all: $(BIN)\n",
    "\n",
    "# Map any file ending in .c to a binary executable\n",
    "# \"$<\" represents the .c file and \"$@\" represents the target binary executable\n",
    "%: %.c\n",
    "\n",
    "\t# Compile the .c file using the gcc compiler with the CFLAGS and links \n",
    "\t# resulting binary with the CURL library\n",
    "\t$(CC) $(CFLAGS) $< -o $@ -lcurl\n",
    "\n",
    "# Clean target which removes specific files\n",
    "clean:\n",
    "\n",
    "\t# Remove the binary file and an \".dSYM\" (debug symbols for debugging) directories\n",
    "\t# the RM command used -r to remove directories and -f to force delete\n",
    "\t$(RM) -rf $(BIN) *.dSYM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command is used again to create the .c file that contains the code for the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file api_data.c\n",
    "\n",
    "#include <curl/curl.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "\n",
    "/* CURL program that retrieves API data with added id.\n",
    "Custom property fields can be added */\n",
    "\n",
    "int main (int argc, char* argv[]){\n",
    "    \n",
    "    // If arguments are invalid just return\n",
    "    if (argc < 2){                                                                                      \n",
    "        printf(\"Error. Please try again correctly. (./apidata -id [id])\\n\");\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    // Initialize the CURL HTTP connection\n",
    "    CURL *curl = curl_easy_init();\n",
    "\n",
    "    // bit of the url that are joined together later                                                                      \n",
    "    char api[] = \"https://chroniclingamerica.loc.gov/\";                            \n",
    "    char url[1000];\n",
    "    char label_1[] = \"lccn/\";\n",
    "    char format[] = \".json\";\n",
    "    char default_id[] = \"sn84023600\";\n",
    "\n",
    "    // Check if CURL initialization is a success or not\n",
    "    if (!curl){                                                                                     \n",
    "        fprintf(stderr, \"init failed\\n\");\n",
    "        return EXIT_FAILURE;\n",
    "    }\n",
    "\n",
    "    // Check if default id should be used\n",
    "    if (((argc==2) && (strcmp(argv[1],\"-id\")==0))){\n",
    "        \n",
    "        // Combine all the bits to produce a functioning url\n",
    "        sprintf(url, \"%s%s%s%s\", api, label_1, default_id, format); \n",
    "        \n",
    "    }\n",
    "    \n",
    "    // Check if the conditions match for using a specified id\n",
    "    else if (((argc==3) && (strcmp(argv[1],\"-id\")==0))){\n",
    "        \n",
    "        // Combines all the bits to produce a functioning url\n",
    "        sprintf(url, \"%s%s%s%s\", api, label_1, argv[2], format);                                              \n",
    "    \n",
    "    }\n",
    "\n",
    "    // If the arguments are invalid then return\n",
    "    else {                                                                                              \n",
    "        curl_easy_cleanup(curl);\n",
    "        return 0;\n",
    "    }                                            \n",
    "\n",
    "    // Set the url to which the HTTP request will be sent to\n",
    "    // first parameter is for the initialized curl HTTP request, second for the option to be set, and third for the value to be set\n",
    "    curl_easy_setopt(curl, CURLOPT_URL, url);\n",
    "\n",
    "    // If result is not retrieved then output error\n",
    "    CURLcode result = curl_easy_perform(curl);\n",
    "\n",
    "    // If result is not retrieved then output error\n",
    "    if (result != CURLE_OK){                                                                            \n",
    "        fprintf(stderr, \"download problem: %s\\n\", curl_easy_strerror(result));\n",
    "    }\n",
    "\n",
    "    // Deallocate memory for the CURL connection\n",
    "    curl_easy_cleanup(curl);                                                                            \n",
    "    return EXIT_SUCCESS;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the `make` command to compile our executable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -g -Wall api_data.c -o api_data -lcurl\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the executable with the an LCCN as an input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"place_of_publication\": \"Tuskaloosa [sic], Ala.\", \"lccn\": \"sn84023600\", \"start_year\": \"183?\", \"place\": [\"Alabama--Tuscaloosa--Tuscaloosa\"], \"name\": \"Alabama State intelligencer. [volume]\", \"publisher\": \"T.M. Bradford\", \"url\": \"https://chroniclingamerica.loc.gov/lccn/sn84023600.json\", \"end_year\": \"18??\", \"issues\": [], \"subject\": []}"
     ]
    }
   ],
   "source": [
    "!./api_data -id sn84023600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing into the json output allows data to be extracted using key names as demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32m\"Alabama State intelligencer. [volume]\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!./api_data -id sn84023600 | jq '.[\"name\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32m\"T.M. Bradford\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!./api_data -id sn84023600 | jq '.[\"publisher\"]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to another publication, we can get the 182nd page (seq-182) of the Evening Star newspaper published on November 19, 1961:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"jp2\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://chroniclingamerica.loc.gov/lccn/sn83045462/1961-11-19/ed-1/seq-182.jp2\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"sequence\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m182\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"text\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://chroniclingamerica.loc.gov/lccn/sn83045462/1961-11-19/ed-1/seq-182/ocr.txt\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"url\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://chroniclingamerica.loc.gov/lccn/sn83045462.json\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Evening star. [volume]\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"pdf\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://chroniclingamerica.loc.gov/lccn/sn83045462/1961-11-19/ed-1/seq-182.pdf\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"ocr\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://chroniclingamerica.loc.gov/lccn/sn83045462/1961-11-19/ed-1/seq-182/ocr.xml\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"issue\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"url\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://chroniclingamerica.loc.gov/lccn/sn83045462/1961-11-19/ed-1.json\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"date_issued\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"1961-11-19\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!./api_data -id \"sn83045462/1961-11-19/ed-1/seq-182\" | jq '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also download this page as a PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Call the api to get the pdf link\n",
    "url=$(./api_data -id \"sn83045462/1961-11-19/ed-1/seq-182\" | jq -r '.pdf')\n",
    "\n",
    "# Use the wget function to download the pdf file\n",
    "wget \"$url\" -O file.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Frequency of “University of Alabama” mentions\n",
    "\n",
    "The URL below limits to searching newspapers in the state of Alabama and provides 75 results of “University of Alabama” mentions. Note that phrases can be searched by putting them inside parentheses for the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the directory in the Chronam folder to create a new one for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilize the `%%file` command to create the following makefile, which will compile our program and create an executable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file makefile\n",
    "\n",
    "# Set the variable CC to gcc, which is used to build the program\n",
    "CC=gcc\n",
    "\n",
    "# Enable debugging information and enable all compiler warnings\n",
    "CFLAGS=-g -Wall\n",
    "\n",
    "# Set the bin variable as the name of the binary file we are creating\n",
    "BIN=frequency_of_mentions\n",
    "\n",
    "# Create the binary file with the name we put\n",
    "all: $(BIN)\n",
    "\n",
    "# Map any file ending in .c to a binary executable. \n",
    "# \"$<\" represents the .c file and \"$@\" represents the target binary executable\n",
    "%: %.c\n",
    "\n",
    "\t# Compile the .c file using the gcc compiler with the CFLAGS and links \n",
    "\t# resulting binary with the CURL library\n",
    "\t$(CC) $(CFLAGS) $< -o $@ -lcurl\n",
    "\n",
    "# Clean target which removes specific files\n",
    "clean:\n",
    "\n",
    "\t# Remove the binary file and an \".dSYM\" (debug symbols for debugging) directories\n",
    "\t# the RM command used -r to remove directories and -f to force delete\n",
    "\t$(RM) -rf $(BIN) *.dSYM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%%file` command is used again to create our .c file which contains the code for the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file frequency_of_mentions.c\n",
    "\n",
    "#include <curl/curl.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "\n",
    "/* CURL program that retrieves frequency of mentions with added search id.\n",
    "Custom property fields can be added*/\n",
    "\n",
    "int main (int argc, char* argv[]){\n",
    "    \n",
    "    // If arguments are invalid then return\n",
    "    if (argc < 2) {                                                                                      \n",
    "        printf(\"Error. Please try again correctly. (./frequency_of_mentions -s [s])\\n\");\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    // Initialize the CURL HTTP connection\n",
    "    CURL *curl = curl_easy_init();\n",
    "\n",
    "    // Bits of the url that are joined together later                                                                      \n",
    "    char api[] = \"https://chroniclingamerica.loc.gov/\";                            \n",
    "    char url[1000];\n",
    "    char default_id[] = \"search/pages/results/?state=Alabama&proxtext=(University%20of%20Alabama)&rows=75&format=json\";\n",
    "\n",
    "    // Check if CURL initialization is a success or not\n",
    "    if (!curl) {                                                                                         \n",
    "        fprintf(stderr, \"init failed\\n\");\n",
    "        return EXIT_FAILURE;\n",
    "    }\n",
    "\n",
    "    // Check if default search id should be used\n",
    "    if ((argc==2) && (strcmp(argv[1],\"-s\")==0)) {\n",
    "        \n",
    "        // Combine all the bits to produce a functioning url\n",
    "        sprintf(url, \"%s%s\", api, default_id); \n",
    "        \n",
    "    }\n",
    "    \n",
    "    // Check if the conditions match for using an id specified\n",
    "    else if ((argc==3) && (strcmp(argv[1],\"-s\")==0)) {\n",
    "        \n",
    "        // Combine all the bits to produce a functioning url\n",
    "        sprintf(url, \"%s%s\", api, argv[2]);                                              \n",
    "    \n",
    "    }\n",
    "\n",
    "    // If the arguments are invalid then return\n",
    "    else {                                                                                              \n",
    "        curl_easy_cleanup(curl);\n",
    "        return 0;\n",
    "    }                                            \n",
    "\n",
    "    // Set the url to which the HTTP request will be sent to\n",
    "    // first parameter is for the initialized curl HTTP request, second for the option to be set, and third for the value to be set\n",
    "    curl_easy_setopt(curl, CURLOPT_URL, url);\n",
    "\n",
    "    // If result is not retrieved then output error\n",
    "    CURLcode result = curl_easy_perform(curl);\n",
    "\n",
    "    // If result is not retrieved then output error\n",
    "    if (result != CURLE_OK) {                                                                            \n",
    "        fprintf(stderr, \"download problem: %s\\n\", curl_easy_strerror(result));\n",
    "    }\n",
    "\n",
    "    // Deallocate memory for the CURL connection\n",
    "    curl_easy_cleanup(curl);                                                                            \n",
    "    return EXIT_SUCCESS;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -g -Wall frequency_of_mentions.c -o frequency_of_mentions -lcurl\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output not shown because it is too long\n",
    "!./frequency_of_mentions -s \"search/pages/results/?state=Alabama&proxtext=(University%20of%20Alabama)&rows=75&format=json\" | jq \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the first result from the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output not shown because it is too long\n",
    "!./frequency_of_mentions -s | jq '.[\"items\"][0]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the number of results retrieved by the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;39m75\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!./frequency_of_mentions -s | jq '.[\"items\"] | length'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve each date and store all of them in a file called \"dates.txt\" by using the `tee` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1924-07-13\n",
      "1918-08-18\n",
      "1924-02-24\n",
      "1916-08-06\n",
      "1913-06-18\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Create a list of dates (YYYY-MM-DD) from each item record\n",
    "# Show the first 10 lines\n",
    "# Algorithm adapted from ChatGPT\n",
    "\n",
    "\n",
    "# Create the associative array to store dates\n",
    "dates=(); \n",
    "\n",
    "# Store the number of results retrieved\n",
    "length=$(./frequency_of_mentions -s | jq '.[\"items\"] | length'); \n",
    "\n",
    "for ((i = 0; i < length; i++)); do \n",
    "\n",
    "    # Retrieve the date for each result\n",
    "    date=$(./frequency_of_mentions -s | jq \".items[$i].date\")\n",
    "    \n",
    "    # Sleep delay\n",
    "    sleep 1\n",
    "    \n",
    "    # Modify the data to be yyyy-mm-dd\n",
    "    date=${date//\\\"/}\n",
    "    date=$(date -d \"${date}\" \"+%Y-%m-%d\")\n",
    "    \n",
    "    # Add the \n",
    "    dates+=(\"$date\")\n",
    "        \n",
    "    echo \"${dates[$i]}\"\n",
    "    \n",
    "done | tee \"dates.txt\" | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the data to output the years and the frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1918 2\n",
      "1919 5\n",
      "1910 2\n",
      "1911 5\n",
      "1912 4\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Read the dates in the file and count the number of times a year is repeated\n",
    "# Algorithm adapted from ChatGPT\n",
    "\n",
    "input_file=\"dates.txt\"\n",
    "if [ ! -f \"$input_file\" ]; then\n",
    "    echo \"Input file not found: $input_file\"\n",
    "    exit 1\n",
    "fi\n",
    " \n",
    "# Create an array to store year counts\n",
    "declare -A year_count\n",
    "\n",
    "# Read data from file\n",
    "while read -r date; do\n",
    "    year=\"${date%%-*}\"\n",
    "    \n",
    "    ((year_count[$year]++))\n",
    "done < \"$input_file\"\n",
    "\n",
    "# Print the frequencies\n",
    "for year in \"${!year_count[@]}\"; do\n",
    "    count=\"${year_count[$year]}\"\n",
    "    echo \"$year $count\"\n",
    "done | tee \"frequencies.txt\" | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Sunday Comic Titles in the Age-herald\n",
    "The Age - Herald published comics every Sunday, we will try to extract the titles of those published on page 15 of the 17th October 1897 edition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir title_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd title_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reuse the `api_data.c` program from Step 1 and modify it to give us .txt outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file makefile\n",
    "\n",
    "# Set the variable CC to gcc, which is used to build the program\n",
    "CC=gcc\n",
    "\n",
    "# Enable debugging information and enable all compiler warnings\n",
    "CFLAGS=-g -Wall\n",
    "\n",
    "# Set the bin variable as the name of the binary file we are creating\n",
    "BIN=title_extract\n",
    "\n",
    "# Create the binary file with the name we put\n",
    "all: $(BIN)\n",
    "\n",
    "# Map any file ending in .c to a binary executable. \n",
    "# \"$<\" represents the .c file and \"$@\" represents the target binary executable\n",
    "%: %.c\n",
    "\n",
    "\t# Compile the .c file using the gcc compiler with the CFLAGS and links \n",
    "\t# resulting binary with the CURL library\n",
    "\t$(CC) $(CFLAGS) $< -o $@ -lcurl\n",
    "\n",
    "# Clean target which removes specific files\n",
    "clean:\n",
    "\n",
    "\t# Remove the binary file and an \".dSYM\" (debug symbols for debugging) directories\n",
    "\t# the RM command used -r to remove directories and -f to force delete\n",
    "\t$(RM) -rf $(BIN) *.dSYM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file title_extract.c\n",
    "\n",
    "#include <curl/curl.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "\n",
    "/* CURL program that extracts title from given id. \n",
    "Custom property fields can be added */\n",
    "\n",
    "int main (int argc, char* argv[]) {\n",
    "    \n",
    "    // If arguments are invalid then return\n",
    "    if (argc < 2) {                                                                                      \n",
    "        printf(\"Error. Please try again correctly. (./title_extract -id [id])\\n\");\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    // Initialize the CURL HTTP connection\n",
    "    CURL *curl = curl_easy_init();\n",
    "\n",
    "    // Bits of the url that are joined together later                                                                      \n",
    "    char api[] = \"https://chroniclingamerica.loc.gov/\";                            \n",
    "    char url[1000];\n",
    "    char label_1[] = \"lccn/\";\n",
    "    char default_id[] = \"sn84023600\";\n",
    "\n",
    "    // Check if CURL initialization is a success or not\n",
    "    if (!curl) {                                                                                         \n",
    "        fprintf(stderr, \"init failed\\n\");\n",
    "        return EXIT_FAILURE;\n",
    "    }\n",
    "\n",
    "    // Check if default id should be used\n",
    "    if ((argc==2) && (strcmp(argv[1],\"-id\")==0)) {\n",
    "        \n",
    "        // Combine all the bits to produce a functioning url\n",
    "        sprintf(url, \"%s%s%s\", api, label_1, default_id); \n",
    "        \n",
    "    }\n",
    "    \n",
    "    // Check if the conditions match for using an id specified\n",
    "    else if ((argc==3) && (strcmp(argv[1],\"-id\")==0)) {\n",
    "        \n",
    "        // Combine all the bits to produce a functioning url\n",
    "        sprintf(url, \"%s%s%s\", api, label_1, argv[2]);                                              \n",
    "    \n",
    "    }\n",
    "    \n",
    "    // If the arguments are invalid then return\n",
    "    else {                                                                                              \n",
    "        curl_easy_cleanup(curl);\n",
    "        return 0;\n",
    "    }                                            \n",
    "\n",
    "    // Set the url to which the HTTP request will be sent to\n",
    "    // first parameter is for the initialized curl HTTP request, second for the option to be set, and third for the value to be set\n",
    "    curl_easy_setopt(curl, CURLOPT_URL, url);\n",
    "\n",
    "    // If result is not retrieved then output error\n",
    "    CURLcode result = curl_easy_perform(curl);\n",
    "\n",
    "    // If result is not retrieved then output error\n",
    "    if (result != CURLE_OK) {                                                                            \n",
    "        fprintf(stderr, \"download problem: %s\\n\", curl_easy_strerror(result));\n",
    "    }\n",
    "\n",
    "    // Deallocate memory for the CURL connection\n",
    "    curl_easy_cleanup(curl);                                                                            \n",
    "    return EXIT_SUCCESS;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -g -Wall title_extract.c -o title_extract -lcurl\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SONGS AND THEIR SINGERS.\n",
      "V- —rm QBmAigb* ,-• ... *•** -j.\n",
      "ih\n",
      "” 'Tis hard to give the hand where the heart can never be!”\n",
      "—Punch.\n",
      "A SIMILE FAR FETCHED. A CHANGE OF HEART.\n",
      "Priscilla is my Klondike girl, He—I think I shall have to preach\n",
      "At least I call her so. a bicycle sermon tomorrow advis\n",
      "There's gold in every straggling ing all my parishioners to ride a\n",
      "•i- curl, wheel.\n"
     ]
    }
   ],
   "source": [
    "!./title_extract -id \"sn86072192/1897-10-31/ed-1/seq-14/ocr.txt\" | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to extract the readable date from the text with random characters and non-interpretable characters, we create a bash script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SONGS AND THEIR SINGERS \n",
      "A SIMILE FAR FETCHED  A CHANGE OF HEART \n",
      "THE PUG DOG PAPA S LAMENT \n",
      "TRUE UP TO A CERTAIN POINT  SURE TEST \n",
      "    SCORCHING AFTER NEW YORK S BICYCLE VOTE \n",
      "A HORSE SHOW SUGGESTION \n",
      "VAN WYCK ON ONE WHEEL  GEORGE IN A BROWN STUDY \n",
      "THE DOCTOR S MOTTO  SHREWDNESS NEEDED   X\n",
      "HER REPUTATIONS \n",
      "THE FINAL CALL \n",
      "THE REPLY OF SPAIN \n",
      "LOW RIDES ERECT  GEN  TRACY S CLEVER DODGE \n",
      "WHY HE LIKED IT \n",
      "PAPA KNOWS \n",
      "AN EXCUSE \n",
      "NOT FOR HIM \n",
      "IN THE FIRELIGHT \n",
      "L WHERE NIGHTS LAST SIX MONTHS \n",
      "ALACK  ALACK \n",
      "MUCH THE SAME THING \n",
      "A KLONDIKER \n",
      "THE MAN WHO IS WEARING A DIAMOND RING FOR THE FIRST TIME \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# There is a lot of text here along with random characters and non-interpretable characters.\n",
    "# Our approach here to get some of the titles will be to only keep \n",
    "# uppercase letters and lines that are at least 75% letters\n",
    "# We use an IFS (Internal Field Seperator) to seperate the lines read by a newline\n",
    "# Algorithm adapted from ChatGPT\n",
    "\n",
    "input_text=$(./title_extract -id \"sn86072192/1897-10-31/ed-1/seq-14/ocr.txt\")\n",
    "IFS=$'\\n'\n",
    "\n",
    "for line in $input_text\n",
    "do\n",
    "    line=$(echo \"$line\" | sed 's/[^A-Z]/ /g')\n",
    "    spaces=$(echo \"$line\" | tr -cd ' ' | wc -c)\n",
    "    size=${#line}\n",
    "    letters=$((size - spaces))\n",
    "    \n",
    "    if ((letters * 4 >= size * 3))\n",
    "    then\n",
    "        echo \"$line\"\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Industrialization keywords frequency in the Birmingham Age-herald\n",
    "We will try to obtain the frequency of “Iron” on the front pages of the Birmingham Age- herald newspapers from the year 1900 to 1920 (limited to the first 75 rows for testing here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Industrialization_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Industrialization_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reuse the `frequency_of_mentions.c` program to obtain the frequency of the keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file makefile\n",
    "\n",
    "# Set the variable CC to gcc, which is used to build the program\n",
    "CC=gcc\n",
    "\n",
    "# Enable debugging information and enable all compiler warnings\n",
    "CFLAGS=-g -Wall\n",
    "\n",
    "# Set the bin variable as the name of the binary file we are creating\n",
    "BIN=frequency_of_mentions\n",
    "\n",
    "# Create the binary file with the name we put\n",
    "all: $(BIN)\n",
    "\n",
    "# Map any file ending in .c to a binary executable. \n",
    "# \"$<\" represents the .c file and \"$@\" represents the target binary executable\n",
    "%: %.c\n",
    "\n",
    "\t# Compile the .c file using the gcc compiler with the CFLAGS and links \n",
    "\t# resulting binary with the CURL library\n",
    "\t$(CC) $(CFLAGS) $< -o $@ -lcurl\n",
    "\n",
    "# Clean target which removes specific files\n",
    "clean:\n",
    "\n",
    "\t# Remove the binary file and an \".dSYM\" (debug symbols for debugging) directories\n",
    "\t# the RM command used -r to remove directories and -f to force delete\n",
    "\t$(RM) -rf $(BIN) *.dSYM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file frequency_of_mentions.c\n",
    "\n",
    "#include <curl/curl.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "\n",
    "/* CURL program that retrieves frequency of mentions with added search id.\n",
    "Custom property fields can be added */\n",
    "\n",
    "int main (int argc, char* argv[]) {\n",
    "    \n",
    "    // If arguments are invalid then return\n",
    "    if (argc < 2) {                                                                                      \n",
    "        printf(\"Error. Please try again correctly. (./frequency_of_mentions -s [s])\\n\");\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    // Initialize the CURL HTTP connection\n",
    "    CURL *curl = curl_easy_init();\n",
    "\n",
    "    // Bits of the url that are joined together later                                                                      \n",
    "    char api[] = \"https://chroniclingamerica.loc.gov/\";                            \n",
    "    char url[1000];\n",
    "    char default_id[] = \"search/pages/results/?state=Alabama&proxtext=(University%20of%20Alabama)&rows=75&format=json\";\n",
    "\n",
    "    // Check if CURL initialization is a success or not\n",
    "    if (!curl) {                                                                                         \n",
    "        fprintf(stderr, \"init failed\\n\");\n",
    "        return EXIT_FAILURE;\n",
    "    }\n",
    "\n",
    "    // Check if default search id should be used\n",
    "    if ((argc==2) && (strcmp(argv[1],\"-s\")==0)) {\n",
    "        \n",
    "        // Combine all the bits to produce a functioning url\n",
    "        sprintf(url, \"%s%s\", api, default_id); \n",
    "        \n",
    "    }\n",
    "    \n",
    "    // Check if the conditions match for using an id specified\n",
    "    else if ((argc==3) && (strcmp(argv[1],\"-s\")==0)) {\n",
    "        \n",
    "        // Combine all the bits to produce a functioning url\n",
    "        sprintf(url, \"%s%s\", api, argv[2]);                                              \n",
    "    \n",
    "    }\n",
    "    \n",
    "    // If the arguments are invalid then return\n",
    "    else {                                                                                              \n",
    "        curl_easy_cleanup(curl);\n",
    "        return 0;\n",
    "    }                                            \n",
    "\n",
    "    // Set the url to which the HTTP request will be sent to\n",
    "    // first parameter is for the initialized curl HTTP request, second for the option to be set, and third for the value to be set\n",
    "    curl_easy_setopt(curl, CURLOPT_URL, url);\n",
    "\n",
    "    // If result is not retrieved then output error\n",
    "    CURLcode result = curl_easy_perform(curl);\n",
    "\n",
    "    // If result is not retrieved then output error\n",
    "    if (result != CURLE_OK) {                                                                            \n",
    "        fprintf(stderr, \"download problem: %s\\n\", curl_easy_strerror(result));\n",
    "    }\n",
    "\n",
    "    // Deallocate memory for the CURL connection\n",
    "    curl_easy_cleanup(curl);                                                                            \n",
    "    return EXIT_SUCCESS;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -g -Wall frequency_of_mentions.c -o frequency_of_mentions -lcurl\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Output not shown because it is too long\n",
    "!./frequency_of_mentions -s \"search/pages/results/?state=Alabama&lccn=sn85038485&dateFilterType=yearRange&date1=1900&date2=1920&sequence=1&andtext=Iron&rows=75&searchType=advanced&format=json\" | jq '.[\"items\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1909-01-13\n",
      "1912-01-23\n",
      "1917-03-10\n",
      "1906-08-16\n",
      "1909-06-26\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Create a list of dates (YYYY-MM-DD) from each item record\n",
    "dates=()\n",
    "\n",
    "# Calculate the length of the dois\n",
    "length=$(./frequency_of_mentions -s \"search/pages/results/?state=Alabama&lccn=sn85038485&dateFilterType=yearRange&date1=1900&date2=1920&sequence=1&andtext=Iron&rows=75&searchType=advanced&format=json\" | jq '.[\"items\"] | length')\n",
    "\n",
    "# Sleep delay\n",
    "sleep 1\n",
    "\n",
    "for ((i = 0; i < length; i++)); do \n",
    "    \n",
    "    date=$(./frequency_of_mentions -s \"search/pages/results/?state=Alabama&lccn=sn85038485&dateFilterType=yearRange&date1=1900&date2=1920&sequence=1&andtext=Iron&rows=75&searchType=advanced&format=json\" | jq \".items[$i].date\")\n",
    "    \n",
    "    # Sleep delay\n",
    "    sleep 1\n",
    "    \n",
    "    date=${date//\\\"/}\n",
    "    date=$(date -d \"${date}\" \"+%Y-%m-%d\")\n",
    "    dates+=(\"$date\")\n",
    "    echo \"${dates[$i]}\"\n",
    "    \n",
    "done | tee \"dates.txt\" | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 dates.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l dates.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the data to output the years and the frequency and store them in a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1910 1\n",
      "1911 10\n",
      "1912 4\n",
      "1913 4\n",
      "1914 2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Read the dates in the file and count the number of times a year is repeated\n",
    "# useful for plotting graphs\n",
    "# Algorithm adapted from ChatGPT\n",
    "\n",
    "input_file=\"dates.txt\"\n",
    "if [ ! -f \"$input_file\" ]; then\n",
    "    echo \"Input file not found: $input_file\"\n",
    "    exit 1\n",
    "fi\n",
    " \n",
    "# Create an array to store year counts\n",
    "declare -A year_count\n",
    "\n",
    "# Read data from file\n",
    "while read -r date; do\n",
    "    year=\"${date%%-*}\"\n",
    "    \n",
    "    ((year_count[$year]++))\n",
    "done < \"$input_file\"\n",
    "\n",
    "# Print the first 5 frequencies\n",
    "for year in \"${!year_count[@]}\"; do\n",
    "    count=\"${year_count[$year]}\"\n",
    "    echo \"$year $count\"\n",
    "done | tee \"frequencies.txt\" | head -n 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
